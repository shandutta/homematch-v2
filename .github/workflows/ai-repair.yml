name: ðŸ¤– AI Repair Agent

on:
  workflow_run:
    workflows: ["Tests & Build Pipeline"]
    types:
      - completed

permissions:
  actions: read
  contents: read

jobs:
  analyze-failure:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    steps:
      - name: Download job artifacts (if any)
        uses: actions/download-artifact@v4
        with:
          run-id: ${{ github.event.workflow_run.id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          path: ./downloaded-artifacts
          pattern: ci-logs-*
          if-no-artifact-found: ignore
          
      - name: Analyze with LLM
        uses: actions/github-script@v7
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        with:
          script: |
            const fs = require('fs');
            const fsp = fs.promises;
            const path = require('path');
            const zlib = require('zlib');

            const runId = context.payload.workflow_run.id;
            const owner = context.repo.owner;
            const repo = context.repo.repo;

            // Collect all jobs for the workflow run
            const jobs = await github.paginate(
              github.rest.actions.listJobsForWorkflowRun,
              { owner, repo, run_id: runId }
            );

            const failedJob = jobs.find(j => j.conclusion === 'failure');
            if (!failedJob) {
              console.log('No failed job found to analyze.');
              return;
            }

            // Pull the failed job log directly from the Actions API
            let jobLogSnippet = '';
            try {
              const logResponse = await github.request(
                'GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs',
                { owner, repo, job_id: failedJob.id }
              );

              const buffer = Buffer.isBuffer(logResponse.data)
                ? logResponse.data
                : Buffer.from(logResponse.data);

              const fullLog = zlib.unzipSync(buffer).toString('utf-8');
              jobLogSnippet = fullLog.slice(-8000); // last 8k chars is usually enough context
            } catch (error) {
              console.log('Could not fetch job log via API:', error.message);
            }

            // Gather any downloaded artifact logs
            const artifactRoot = path.join(process.cwd(), 'downloaded-artifacts');
            let artifactLogs = '';

            async function collectLogs(dir) {
              const entries = await fsp.readdir(dir, { withFileTypes: true });
              for (const entry of entries) {
                const entryPath = path.join(dir, entry.name);
                if (entry.isDirectory()) {
                  await collectLogs(entryPath);
                  continue;
                }

                if (/\.(log|txt|out)$/i.test(entry.name)) {
                  try {
                    const content = await fsp.readFile(entryPath, 'utf8');
                    artifactLogs += `\n# ${path.relative(artifactRoot, entryPath)}\n${content}`;
                  } catch (readErr) {
                    console.log(`Could not read ${entryPath}:`, readErr.message);
                  }
                }
              }
            }

            if (fs.existsSync(artifactRoot)) {
              try {
                await collectLogs(artifactRoot);
              } catch (err) {
                console.log('Error while collecting artifact logs:', err.message);
              }
            }

            const runUrl = context.payload.workflow_run.html_url;
            const combinedLog = jobLogSnippet || artifactLogs || 'No logs available from the failed job.';

            if (!process.env.OPENROUTER_API_KEY) {
              console.log('No OpenRouter Key found. Skipping AI analysis.');
              return;
            }

            const prompt = [
              'CI workflow failed.',
              `Run: ${runUrl}`,
              `Failed job: ${failedJob.name}`,
              `Head SHA: ${context.payload.workflow_run.head_sha}`,
              '',
              '===== LOG SNIPPET =====',
              combinedLog
            ].join('\n');

            try {
              const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  model: 'google/gemini-flash-1.5',
                  temperature: 0.2,
                  max_tokens: 600,
                  messages: [
                    {
                      role: 'system',
                      content: 'You are a senior software engineer. Analyze the CI failure log and return the likely root cause and concrete steps to fix it. Be concise.'
                    },
                    {
                      role: 'user',
                      content: prompt
                    }
                  ]
                })
              });
              
              if (!response.ok) {
                throw new Error(`OpenRouter responded with ${response.status}`);
              }

              const data = await response.json();
              const analysis = data.choices?.[0]?.message?.content;

              if (!analysis) {
                console.log('OpenRouter returned no analysis.');
                return;
              }

              console.log('AI Analysis:\n', analysis);

              // Add the analysis to the workflow summary for quick visibility
              await core.summary
                .addHeading('AI Repair Analysis')
                .addRaw(analysis.replace(/\n/g, '<br/>'))
                .write();

            } catch (error) {
              console.error('Error calling LLM:', error);
            }
